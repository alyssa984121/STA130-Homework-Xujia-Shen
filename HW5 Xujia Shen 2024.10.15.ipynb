{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c22ec85",
   "metadata": {},
   "source": [
    "# Q1\n",
    "\n",
    "#### What is the key factor that makes the difference between ideas that can, and cannot be examined and tested statistically?\n",
    "\n",
    "The key factor is whether the idea is measurable. For an idea to be tested statistically, it must be expressed in terms of variables that can be observed, measured, and compared using data. If an idea can’t be quantified or leads to subjective outcomes, it cannot be tested statistically.\n",
    "\n",
    "#### What would you describe is the key \"criteria\" defining what a good null hypothesis is?\n",
    "\n",
    "A good null hypothesis should be clear and specific, directly stating what is being tested. It must also be testable using statistical methods, and it should represent a position of no effect or relationship between variables, assuming that any observed differences are due to random chance.\n",
    "\n",
    "####  What is the difference between a null hypothesis and an alternative hypothesis in the context of hypothesis testing? \n",
    "\n",
    "The null hypothesis (H₀) is a statement suggesting that there is no effect or no difference. It acts as a default position, indicating that any variations are due to random chance. The alternative hypothesis (HA) is the opposite—it claims that there is an effect or a difference. It is what researchers hope to prove or demonstrate through their analysis. In hypothesis testing, researchers aim to determine whether we can reject the null hypothesis in favor of the alternative based on the evidence provided by the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd7c6e4",
   "metadata": {},
   "source": [
    "### Chat history Q1:\n",
    "LINK:https://chatgpt.com/share/670cb731-b578-8004-8acf-e9a2d649c609\n",
    "\n",
    "SUMMARY:We discussed the key concepts of hypothesis testing. Specifically, we talked about how ideas must be measurable and quantifiable to be testable using statistics. A good null hypothesis is one that is precise, testable, and neutral, assuming no effect or difference. We also distinguished between the null hypothesis (H₀), which assumes no effect, and the alternative hypothesis (H₁), which suggests there is an effect or difference. Finally, we emphasized that statistical testing is only possible when data can be collected and measured to test these hypotheses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ea2e72",
   "metadata": {},
   "source": [
    "## Q2\n",
    "Population: This is the entire group we're interested in studying (for example, all adults in a country).\n",
    "Sample: Since we usually can't study the whole population, we collect data from a smaller group called a sample (like 100 randomly selected adults).\n",
    "Sample values (xi): These are the individual data points in the sample, like the height of each person.\n",
    "Sample mean (x̄): This is the average of all the values in the sample. It helps us estimate the average of the population.\n",
    "Population mean (μ): This is the true average for the entire population, which we usually don’t know.\n",
    "Hypothesized population mean (μ₀): In hypothesis testing, we make a guess about what the population mean might be. This is called the null hypothesis, and we test whether this guess (μ₀) is likely to be true.\n",
    "When we collect data, we usually gather it from a sample, which is a small part of the larger population we’re interested in. For example, if we want to know the average height of all adults in a country (the population), it would be too difficult to measure every single person, so we measure a smaller group, say 100 adults, which is our sample.\n",
    "\n",
    "From this sample, we can calculate the sample mean (x̄), which is the average of the heights in that sample. This gives us a rough estimate of the population mean (μ)—the true average height for the entire population—but it’s not exact because we’re only using a small portion of the population.\n",
    "\n",
    "Now, when we perform a hypothesis test, we’re trying to figure out if the true population mean (μ) is equal to a specific value we’ve guessed, called the null hypothesis (μ₀). The test helps us decide if the sample we’ve collected provides enough evidence to reject this guess. But, importantly, the result of the test isn’t just about our sample—it’s about the entire population.\n",
    "\n",
    "So, even though we use the sample mean (x̄) to do the test, the result tells us something about the population mean (μ). In other words, we use the small group (sample) to draw conclusions about the whole group (population).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1652af89",
   "metadata": {},
   "source": [
    "LINK:https://chatgpt.com/share/670f3160-eb18-8004-95d8-643921a90e75\n",
    "SUMMARY:\n",
    "Here's a summary of our chat history:\n",
    "\n",
    "You started by asking for help understanding a sentence from a pre-lecture video about hypothesis testing, specifically regarding the difference between sample statistics and population parameters. You were looking for a detailed explanation of terms like **xi's** (individual sample values), **x̄** (sample mean), **μ** (population mean), and **μ₀** (hypothesized population mean), and how they relate to hypothesis testing.\n",
    "\n",
    "I explained that in hypothesis testing, we use the **sample mean (x̄)** to make inferences about the **population mean (μ)**, and the test results refer to the population, not just the sample. I broke down the terms, discussed the framework of null and alternative hypotheses, and emphasized that hypothesis testing is about deciding if the **population mean (μ)** differs from the **hypothesized value (μ₀)** based on the **sample data**.\n",
    "\n",
    "You requested a more detailed and specific explanation, and I provided a deeper dive into how hypothesis testing works, highlighting how sample data (like **x̄**) is used to draw conclusions about the population parameter (like **μ**), using an example involving average height to illustrate the process.\n",
    "\n",
    "Finally, you asked for a summary of our discussion, which I’ve provided here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92b6f82",
   "metadata": {},
   "source": [
    "## Q3\n",
    "\n",
    "When we calculate a p-value, we start by assuming that the null hypothesis is true, which means we’re considering a situation where there’s no real effect or difference happening. This step is crucial because it helps us understand how likely our observed data is under this assumption.\n",
    "\n",
    "The key idea here is the sampling distribution of the test statistic when the null hypothesis holds. This distribution shows us how the test statistic would behave if we repeatedly sampled from the same population. By comparing our observed result to this distribution, we can see how unusual or typical our data really is.\n",
    "\n",
    "For instance, if our test statistic falls into the extreme ends of the distribution, it indicates that what we observed is quite rare under the null hypothesis. This suggests that maybe the null hypothesis isn’t a good explanation for what we’re seeing, prompting us to consider rejecting it. On the other hand, if our result is more towards the center of the distribution, it implies that our data is fairly common, and we don’t have enough evidence to reject the null hypothesis.\n",
    "\n",
    "So, by imagining a world where the null hypothesis is true, we can better assess how surprising our findings are, which helps us decide whether to stick with the null hypothesis or to question it based on the evidence we have."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cad3f5",
   "metadata": {},
   "source": [
    "## Q4\n",
    "\n",
    "When we perform a hypothesis test, we start by assuming the null hypothesis is true. Under this assumption, we can calculate the sampling distribution of the test statistic. This sampling distribution represents all the possible values the test statistic could take if the null hypothesis were true, and it shows us what is expected by chance alone.\n",
    "\n",
    "The observed test statistic is what we calculate from our actual data. To assess how unusual this value is, we compare it to the sampling distribution. If the observed test statistic falls near the center of this distribution, it indicates that the result is typical and consistent with the null hypothesis. However, if the observed test statistic falls far into the tails of the distribution (meaning it is very large or very small compared to most values), it suggests that such an outcome is unlikely if the null hypothesis were true.\n",
    "\n",
    "This is where the p-value comes in. The p-value tells us the probability of observing a test statistic as extreme as, or more extreme than, the one we got, given that the null hypothesis is true. A **small p-value** means that our observed test statistic is far out in the tails of the sampling distribution, making it unlikely that this result would occur by chance under the null hypothesis.\n",
    "\n",
    "Thus, a smaller p-value indicates stronger evidence against the null hypothesis because the observed test statistic is far from what we would expect under that hypothesis. The more extreme the test statistic, the less believable the null hypothesis becomes. In this way, a small p-value makes the null hypothesis look \"ridiculous,\" since it suggests that the observed data is highly inconsistent with what we would expect if the null hypothesis were true.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5ccdb31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated p-value: 0.0005\n"
     ]
    }
   ],
   "source": [
    "#Q5\n",
    "#To investigate whether kissing couples show a tendency to tilt their heads to the right, we can simulate a p-value under the null hypothesis 𝐻0, which assumes no preference for head tilt direction:\n",
    "\n",
    "#H0: p=0.5 Ha:p!=0.5\n",
    "\n",
    "#-Simulation Setup: Using a “50/50 coin-flipping” model, we simulate 124 couples, with each couple having an equal chance of tilting their head to the right or left.\n",
    "\n",
    "#-Outcome Count: We run multiple simulations (e.g., 10,000) and count the number of simulations where 80 or more couples tilt their heads to the right, as observed in the study (64.5% tilted right).\n",
    "\n",
    "#-Calculate the p-value: The p-value is the proportion of simulations where 80 or more couples tilt right, indicating the likelihood of observing this result if the null hypothesis is true.\n",
    "\n",
    "#-Interpretation: According to the provided evidence table, a small p-value would suggest strong evidence against 𝐻0. For example, if 𝑝≤0.01, this would be considered strong evidence against the null hypothesis, suggesting that the observed head tilt preference is unlikely to be due to random chance alone.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "num_couples = 124  # Total number of couples\n",
    "observed_right_tilts = 80  # Number of couples who tilted to the right\n",
    "num_simulations = 10000  # Number of simulations to run\n",
    "p_right = 0.5  # Probability of tilting right under the null hypothesis\n",
    "\n",
    "simulated_counts = np.random.binomial(num_couples, p_right, num_simulations)\n",
    "\n",
    "p_value = np.mean(simulated_counts >= observed_right_tilts)\n",
    "\n",
    "print(\"Simulated p-value:\", p_value)\n",
    "\n",
    "#As a result, we reject H0 and conclude Ha. Since p-value 0.0007, is less than 0.001, we have very strong evidence against the null hypothesis, \n",
    "#and say that p!=0.5, shich means the head tilted to left or right is not a random preference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3589599",
   "metadata": {},
   "source": [
    "## Q6\n",
    "\n",
    "A smaller p-value does not definitively prove that the null hypothesis is false. Instead, it provides evidence that the observed data is less likely if the null hypothesis were true, prompting us to question its validity. However, it does not offer absolute proof.\n",
    "\n",
    "In the case of Fido, a p-value can’t definitively prove Fido's innocence or guilt. A low p-value suggests that the evidence against Fido being innocent (the null hypothesis) is strong, but it doesn't confirm guilt beyond all doubt. Conversely, a high p-value doesn't prove innocence but rather suggests insufficient evidence to reject the null hypothesis.\n",
    "\n",
    "P-values do not provide conclusive proof; they measure the strength of evidence. There is no specific threshold at which a p-value can definitively establish guilt or innocence because statistical significance does not equate to absolute certainty.\n",
    "\n",
    "Moreover, ther might be Type I and Type II error. A Type I error occurs when we reject the null hypothesis (𝐻0) when it is actually true. A Type II error occurs when we fail to reject the null hypothesis when the alternative hypothesis (𝐻𝑎) is actually true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42ca13b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-Tailed Test (greater than):\n",
      "Number of Simulations: 10000\n",
      "Number of simulated statistics under H0 that are greater than or equal to the observed statistic: 6146\n",
      "p-value (one-tailed): 0.6146\n"
     ]
    }
   ],
   "source": [
    "#Q7\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(45)  \n",
    "patient_data = pd.DataFrame({'HealthScoreChange': np.random.normal(0, 1, 10)})\n",
    "\n",
    "np.random.seed(1)  \n",
    "number_of_simulations = 10000\n",
    "n_size = len(patient_data)\n",
    "population_parameter_value_under_H0 = 0.5\n",
    "\n",
    "IncreaseProportionSimulations_underH0random = np.zeros(number_of_simulations)\n",
    "for i in range(number_of_simulations):\n",
    "    random_improvement = np.random.choice([0, 1], size=n_size, replace=True)\n",
    "    IncreaseProportionSimulations_underH0random[i] = random_improvement.mean()\n",
    "\n",
    "# Observed statistic: proportion of patients with positive health score change\n",
    "observed_statistic = (patient_data['HealthScoreChange'] > 0).mean()\n",
    "\n",
    "# One-tailed test: count how many simulated proportions are greater than or equal to the observed statistic\n",
    "SimStats_greater_than_ObsStat = IncreaseProportionSimulations_underH0random >= observed_statistic\n",
    "p_value = SimStats_greater_than_ObsStat.sum() / number_of_simulations\n",
    "\n",
    "print(\"One-Tailed Test (greater than):\")\n",
    "print(\"Number of Simulations:\", number_of_simulations)\n",
    "print(\"Number of simulated statistics under H0 that are greater than or equal to the observed statistic:\", SimStats_greater_than_ObsStat.sum())\n",
    "print(\"p-value (one-tailed):\", p_value)\n",
    "\n",
    "\n",
    "\n",
    "#Explanation of the changes:\n",
    "#The primary change in the code involves switching the computation from checking both tails of the distribution (two-tailed test) to focusing on just one tail (one-tailed test).\n",
    "#The p-value calculation now uses SimStats_greater_than_ObsStat, \n",
    "#which only considers simulations where the simulated statistic is greater than or equal to the observed statistic.\n",
    "\n",
    "#The p-value is smaller than the original one. \n",
    "#Because the one-tailed test only considers deviations in one specific direction. \n",
    "#In a two-tailed test, we assess whether the observed statistic is significantly different (either greater or lesser) from the null hypothesis value, doubling the extreme regions we’re interested in. \n",
    "#This means that the p-value includes the probabilities of deviations on both sides of the distribution.\n",
    "#In contrast, a one-tailed test focuses only on deviations in one direction—either greater than or less than the null hypothesis value—depending on our hypothesis. \n",
    "#This halves the area we’re evaluating under the curve, leading to a lower p-value for a given observed statistic if it falls in the specified tail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd8ea61",
   "metadata": {},
   "source": [
    "Q7 CHAT HISTORY\n",
    "LINK:https://chatgpt.com/share/670f364b-bc34-8004-a671-643355d31f3a\n",
    "    \n",
    "SUMMARY: Certainly! In our conversation, we discussed how to analyze the effectiveness of a new vaccine developed by AliTech using a dataset that includes patient health scores before and after vaccination. You provided specific guidance on using a simulation approach to calculate a one-tailed p-value for the hypothesis test instead of the two-tailed version typically demonstrated in a previous tutorial.\n",
    "\n",
    "We structured the analysis by first defining the null and alternative hypotheses, loading the patient data into a Pandas DataFrame, and calculating the change in health scores. Then, we set up a simulation using NumPy to estimate the proportion of improvement under the null hypothesis. We calculated the actual improvement proportion and determined the one-tailed p-value by comparing it against the simulated data.\n",
    "\n",
    "Overall, we aimed to effectively demonstrate how to assess the vaccine's impact while adhering to the coding style you provided, emphasizing the interpretation of the results based on the p-value obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "747067ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated p-value: 0.0298\n"
     ]
    }
   ],
   "source": [
    "#Q8\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(130)\n",
    "num_students = 80\n",
    "observed_correct = 49\n",
    "p_null = 0.5\n",
    "num_simulations = 10000\n",
    "\n",
    "simulated_counts = np.random.binomial(num_students, p_null, num_simulations)\n",
    "simulated_proportions = simulated_counts / num_students\n",
    "\n",
    "observed_proportion = observed_correct / num_students\n",
    "p_value = np.mean(simulated_proportions >= observed_proportion)\n",
    "\n",
    "print(\"Simulated p-value:\", p_value)\n",
    "\n",
    "\n",
    "#Null Hypothesis (𝐻0): The proportion of students who can correctly identify the order of pouring is due to random guessing, meaning 𝑝=0.5.\n",
    "#Alternative Hypothesis (𝐻𝑎): The proportion of students who can correctly identify the order of pouring is greater than random guessing, meaning 𝑝>0.5\n",
    "#Since this p-value 0.0298 is less than the significance level of 0.05, \n",
    "#which suggests that achieving the observed proportion by random chance alone is unlikely, providing evidence against the null hypothesis.\n",
    "#There is enough evidence to reject 𝐻0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256daf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q9\n",
    "YES."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
